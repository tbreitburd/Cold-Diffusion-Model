{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p contents_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def generate_order(T):\n",
    "    half_point = T // 2 - 1\n",
    "    backward = list(range(half_point, -1, -1))\n",
    "    forward = list(range(half_point + 1, T))\n",
    "    print(forward, backward)\n",
    "    order = []\n",
    "    for i in range(half_point + 1):\n",
    "        order.append(forward[i])\n",
    "        order.append(backward[i])\n",
    "\n",
    "    if T % 2 == 1:\n",
    "        order.append(forward[-1])\n",
    "\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_schedules(order: int, T: int) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Returns order and schedule for each row in the image.\"\"\"\n",
    "\n",
    "    assert order == 1 or order == 2, \"Order must be either 1 or 2\"\n",
    "\n",
    "    half_point = T // 2 - 1\n",
    "    backward = list(range(13, -1, -1))\n",
    "    forward = list(range(13 + 1, 28))\n",
    "    rows = []\n",
    "    if order == 1:\n",
    "        for i in range(half_point + 1):\n",
    "            rows.append(forward[i])\n",
    "            rows.append(backward[i])\n",
    "        if T % 2 == 1:\n",
    "            rows.append(forward[half_point + 1])\n",
    "    if order == 2:\n",
    "        for i in range(1, half_point + 2):\n",
    "            rows.append(backward[-i])\n",
    "            rows.append(forward[-i])\n",
    "        if T % 2 == 1:\n",
    "            rows.append(forward[-half_point - 2])\n",
    "\n",
    "    return {\"rows_t\": torch.tensor(rows)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows_t': tensor([ 0, 27,  1, 26,  2, 25,  3, 24,  4, 23,  5, 22,  6, 21,  7, 20,  8, 19,\n",
      "         9, 18, 10, 17, 11, 16, 12, 15, 14])}\n"
     ]
    }
   ],
   "source": [
    "dod = row_schedules(2, 27)\n",
    "print(dod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14., 14., 14., 14., 14., 14., 14., 14., 14.])\n"
     ]
    }
   ],
   "source": [
    "f = torch.tensor(\n",
    "    [\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        11,\n",
    "        12,\n",
    "        13,\n",
    "        14,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        18,\n",
    "        19,\n",
    "        20,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "        24,\n",
    "        25,\n",
    "        26,\n",
    "        27,\n",
    "    ],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "f = f.view(3, 9)  # Reshape f into a 2D tensor of shape (3, 9)\n",
    "row = torch.mean(f[1]).expand_as(f[1])\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        *,\n",
    "        expected_shape,\n",
    "        act=nn.GELU,\n",
    "        kernel_size=7,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.LayerNorm((out_channels, *expected_shape)),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        expected_shape=(28, 28),\n",
    "        n_hidden=(64, 128, 64),\n",
    "        kernel_size=7,\n",
    "        last_kernel_size=3,\n",
    "        time_embeddings=16,\n",
    "        act=nn.GELU,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        last = in_channels\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for hidden in n_hidden:\n",
    "            self.blocks.append(\n",
    "                CNNBlock(\n",
    "                    last,\n",
    "                    hidden,\n",
    "                    expected_shape=expected_shape,\n",
    "                    kernel_size=kernel_size,\n",
    "                    act=act,\n",
    "                )\n",
    "            )\n",
    "            last = hidden\n",
    "\n",
    "        # The final layer, we use a regular Conv2d to get the\n",
    "        # correct scale and shape (and avoid applying the activation)\n",
    "        self.blocks.append(\n",
    "            nn.Conv2d(\n",
    "                last,\n",
    "                in_channels,\n",
    "                last_kernel_size,\n",
    "                padding=last_kernel_size // 2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ## This part is literally just to put the single scalar \"t\" into the CNN\n",
    "        ## in a nice, high-dimensional way:\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(time_embeddings * 2, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, n_hidden[0]),\n",
    "        )\n",
    "        frequencies = torch.tensor(\n",
    "            [0] + [2 * np.pi * 1.5**i for i in range(time_embeddings - 1)]\n",
    "        )\n",
    "        self.register_buffer(\"frequencies\", frequencies)\n",
    "\n",
    "    def time_encoding(self, t: int) -> torch.Tensor:\n",
    "        phases = torch.concat(\n",
    "            (\n",
    "                torch.sin(t * self.frequencies[None, :]),\n",
    "                torch.cos(t * self.frequencies[None, :]) - 1,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        return self.time_embed(phases)[:, :, None, None]\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # Shapes of input:\n",
    "        #    x: (batch, chan, height, width)\n",
    "        #    t: (batch,)\n",
    "\n",
    "        embed = self.blocks[0](x)\n",
    "        # ^ (batch, n_hidden[0], height, width)\n",
    "\n",
    "        # Add information about time along the diffusion process\n",
    "        #  (Providing this information by superimposing in latent space)\n",
    "        embed += self.time_encoding(t)\n",
    "        #         ^ (batch, n_hidden[0], 1, 1) - thus, broadcasting\n",
    "        #           to the entire spatial domain\n",
    "\n",
    "        for block in self.blocks[1:]:\n",
    "            embed = block(embed)\n",
    "\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Row_Averaging(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gt,\n",
    "        row_order: int,\n",
    "        n_T: int,\n",
    "        criterion: nn.Module = nn.MSELoss(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.gt = gt\n",
    "\n",
    "        row_schedule = row_schedules(row_order, n_T)\n",
    "\n",
    "        # `register_buffer` will track these tensors for device placement, but\n",
    "        # not store them as model parameters. This is useful for constants.\n",
    "        self.register_buffer(\"rows_t\", row_schedule[\"rows_t\"])\n",
    "        self.rows_t  # Exists! Set by register_buffer\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Row averaging diffusion\"\"\"\n",
    "\n",
    "        t = torch.randint(1, self.n_T, (1,), device=x.device).item()\n",
    "\n",
    "        rows_t = self.rows_t[:t]\n",
    "\n",
    "        z_t = torch.empty_like(x)\n",
    "\n",
    "        for i in range(28):\n",
    "            if i in rows_t:\n",
    "                z_t[i] = torch.mean(x[i]).expand_as(x[i])\n",
    "            else:\n",
    "                z_t[i] = x[i]\n",
    "        # We should predict the \"error term\" from this z_t. Loss is what we return.\n",
    "\n",
    "        return self.criterion(x, self.gt(z_t, t / self.n_T))\n",
    "\n",
    "    def degrade(self, x: torch.Tensor, t: int) -> torch.Tensor:\n",
    "        \"\"\"Row averaging diffusion for a set time step\"\"\"\n",
    "\n",
    "        rows_t = self.rows_t[:t]\n",
    "\n",
    "        z_t = torch.empty_like(x)\n",
    "\n",
    "        for i in range(28):\n",
    "            if i in rows_t:\n",
    "                z_t[i] = torch.mean(x[i]).expand_as(x[i])\n",
    "            else:\n",
    "                z_t[i] = x[i]\n",
    "\n",
    "        return z_t\n",
    "\n",
    "    def sample(self, n_sample: int, dataset, size, device) -> torch.Tensor:\n",
    "        \"\"\"Algorithm 2 in Bansal et al. (2022)\"\"\"\n",
    "\n",
    "        num_images = len(dataset)\n",
    "        idx = random.sample(range(num_images), n_sample)\n",
    "        z_t = torch.stack([dataset[i][0].clone() for i in idx])\n",
    "        print(z_t.shape)\n",
    "\n",
    "        for i in range(n_sample):\n",
    "            rows_t = self.rows_t[: self.n_T]\n",
    "\n",
    "            for j in range(28):\n",
    "                if j in rows_t:\n",
    "                    z_t[i, j, :] = torch.mean(z_t[i, j, :]).expand_as(z_t[i, j, :])\n",
    "                else:\n",
    "                    z_t[i, j, :] = z_t[i, j, :]\n",
    "\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            x_hat = self.gt(z_t, i / self.n_T)\n",
    "            z_t -= Row_Averaging.degrade[x_hat, i] - Row_Averaging.degrade(x_hat, i - 1)\n",
    "\n",
    "        return z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrade_mnist(dataset, n_sample: int):\n",
    "    num_images = len(dataset)\n",
    "    idx = random.sample(range(num_images), n_sample)\n",
    "    real_img = torch.stack([dataset[i][0].clone() for i in idx])\n",
    "\n",
    "    for i in range(n_sample):\n",
    "        rows_t = self.rows_t[:t]\n",
    "\n",
    "        z_t = torch.empty_like(x)\n",
    "\n",
    "        for i in range(28):\n",
    "            if i in rows_t:\n",
    "                z_t[i] = torch.mean(x[i]).expand_as(x[i])\n",
    "            else:\n",
    "                z_t[i] = x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "# For testing: (16, 32, 32, 16)\n",
    "# For more capacity (for example): (64, 128, 256, 128, 64)\n",
    "row_avg = Row_Averaging(gt=gt, row_order=1, n_T=10)\n",
    "optim = torch.optim.Adam(row_avg.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "# We wrap our model, optimizer, and dataloaders with `accelerator.prepare`,\n",
    "# which lets HuggingFace's Accelerate handle the device placement and gradient accumulation.\n",
    "row_avg, optim, dataloader = accelerator.prepare(row_avg, optim, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in dataloader:\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    row_avg(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0652: 100%|██████████| 468/468 [01:28<00:00,  5.30it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m row_avg\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 26\u001b[0m     xh \u001b[38;5;241m=\u001b[39m \u001b[43mrow_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Can get device explicitly with `accelerator.device`\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     grid \u001b[38;5;241m=\u001b[39m make_grid(xh, nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     28\u001b[0m     avg_losses\u001b[38;5;241m.\u001b[39mappend(avg_loss)\n",
      "Cell \u001b[0;32mIn[141], line 72\u001b[0m, in \u001b[0;36mRow_Averaging.sample\u001b[0;34m(self, n_sample, dataset, size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m             z_t[i,j,:] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(z_t[i,j,:])\u001b[38;5;241m.\u001b[39mexpand_as(z_t[i,j,:])\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m             z_t[i,j,:] \u001b[38;5;241m=\u001b[39m \u001b[43mz_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_T, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     76\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt(z_t, i \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_T)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "n_epoch = 2\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    row_avg.train()\n",
    "\n",
    "    pbar = tqdm(dataloader)  # Wrap our loop with a visual progress bar\n",
    "    for x, _ in pbar:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = row_avg(x)\n",
    "\n",
    "        loss.backward()\n",
    "        # ^Technically should be `accelerator.backward(loss)` but not necessary for local training\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        avg_loss = np.average(losses[min(len(losses) - 100, 0) :])\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"loss: {avg_loss:.3g}\"\n",
    "        )  # Show running average of loss in progress bar\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    row_avg.eval()\n",
    "    with torch.no_grad():\n",
    "        xh = row_avg.sample(\n",
    "            16, dataset, (1, 28, 28), accelerator.device\n",
    "        )  # Can get device explicitly with `accelerator.device`\n",
    "        grid = make_grid(xh, nrow=4)\n",
    "        avg_losses.append(avg_loss)\n",
    "        # Save samples to `./contents_custom` directory\n",
    "        save_image(grid, f\"./contents_custom/ddpm_sample_{i:04d}.png\")\n",
    "\n",
    "        # save model\n",
    "        torch.save(row_avg.state_dict(), f\"./ddpm_mnist.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M2CW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
