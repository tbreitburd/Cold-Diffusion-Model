{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p contents_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasbreitburd/anaconda3/envs/M2CW/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def generate_order(T):\n",
    "    half_point = T // 2 - 1\n",
    "    backward = list(range(half_point, -1, -1))\n",
    "    forward = list(range(half_point + 1, T))\n",
    "    print(forward, backward)\n",
    "    order = []\n",
    "    for i in range(half_point + 1):\n",
    "        order.append(forward[i])\n",
    "        order.append(backward[i])\n",
    "\n",
    "    if T % 2 == 1:\n",
    "        order.append(forward[-1])\n",
    "\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_schedules(order: int, T: int) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Returns order and schedule for each row in the image.\"\"\"\n",
    "\n",
    "    assert order == 1 or order == 2, \"Order must be either 1 or 2\"\n",
    "\n",
    "    half_point = T // 2 - 1\n",
    "    backward = list(range(13, -1, -1))\n",
    "    forward = list(range(13 + 1, 28))\n",
    "    rows = []\n",
    "    if order == 1:\n",
    "        for i in range(half_point + 1):\n",
    "            rows.append(forward[i])\n",
    "            rows.append(backward[i])\n",
    "        if T % 2 == 1:\n",
    "            rows.append(forward[half_point + 1])\n",
    "    if order == 2:\n",
    "        for i in range(1, half_point + 2):\n",
    "            rows.append(backward[-i])\n",
    "            rows.append(forward[-i])\n",
    "        if T % 2 == 1:\n",
    "            rows.append(forward[-half_point - 2])\n",
    "    else:\n",
    "        # Unique random order\n",
    "        rows = random.sample(range(28), 28)\n",
    "\n",
    "    return {\"rows_t\": torch.tensor(rows)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        *,\n",
    "        expected_shape,\n",
    "        act=nn.GELU,\n",
    "        kernel_size=7,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.LayerNorm((out_channels, *expected_shape)),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        expected_shape=(28, 28),\n",
    "        n_hidden=(64, 128, 64),\n",
    "        kernel_size=7,\n",
    "        last_kernel_size=3,\n",
    "        time_embeddings=16,\n",
    "        act=nn.GELU,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        last = in_channels\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for hidden in n_hidden:\n",
    "            self.blocks.append(\n",
    "                CNNBlock(\n",
    "                    last,\n",
    "                    hidden,\n",
    "                    expected_shape=expected_shape,\n",
    "                    kernel_size=kernel_size,\n",
    "                    act=act,\n",
    "                )\n",
    "            )\n",
    "            last = hidden\n",
    "\n",
    "        # The final layer, we use a regular Conv2d to get the\n",
    "        # correct scale and shape (and avoid applying the activation)\n",
    "        self.blocks.append(\n",
    "            nn.Conv2d(\n",
    "                last,\n",
    "                in_channels,\n",
    "                last_kernel_size,\n",
    "                padding=last_kernel_size // 2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ## This part is literally just to put the single scalar \"t\" into the CNN\n",
    "        ## in a nice, high-dimensional way:\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(time_embeddings * 2, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, n_hidden[0]),\n",
    "        )\n",
    "        frequencies = torch.tensor(\n",
    "            [0] + [2 * np.pi * 1.5**i for i in range(time_embeddings - 1)]\n",
    "        )\n",
    "        self.register_buffer(\"frequencies\", frequencies)\n",
    "\n",
    "    def time_encoding(self, t: int) -> torch.Tensor:\n",
    "        phases = torch.concat(\n",
    "            (\n",
    "                torch.sin(t[:, None] * self.frequencies[None, :]),\n",
    "                torch.cos(t[:, None] * self.frequencies[None, :]) - 1,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        return self.time_embed(phases)[:, :, None, None]\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # Shapes of input:\n",
    "        #    x: (batch, chan, height, width)\n",
    "        #    t: (batch,)\n",
    "\n",
    "        embed = self.blocks[0](x)\n",
    "        # ^ (batch, n_hidden[0], height, width)\n",
    "\n",
    "        # Add information about time along the diffusion process\n",
    "        #  (Providing this information by superimposing in latent space)\n",
    "        embed += self.time_encoding(t)\n",
    "        #         ^ (batch, n_hidden[0], 1, 1) - thus, broadcasting\n",
    "        #           to the entire spatial domain\n",
    "\n",
    "        for block in self.blocks[1:]:\n",
    "            embed = block(embed)\n",
    "\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Row_Averaging(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gt,\n",
    "        row_order: int,\n",
    "        n_T: int,\n",
    "        criterion: nn.Module = nn.MSELoss(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.gt = gt\n",
    "\n",
    "        row_schedule = row_schedules(row_order, n_T)\n",
    "\n",
    "        # `register_buffer` will track these tensors for device placement, but\n",
    "        # not store them as model parameters. This is useful for constants.\n",
    "        self.register_buffer(\"rows_t\", row_schedule[\"rows_t\"])\n",
    "        self.rows_t  # Exists! Set by register_buffer\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Row averaging diffusion\"\"\"\n",
    "\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        z_t = x\n",
    "        for idx in t:\n",
    "            rows_t = self.rows_t[:idx]\n",
    "            z_t[:, :, rows_t, :] = torch.mean(\n",
    "                z_t[:, :, rows_t, :], dim=2, keepdim=True\n",
    "            ).expand_as(z_t[:, :, rows_t, :])\n",
    "\n",
    "        # We should predict the \"error term\" from this z_t. Loss is what we return.\n",
    "\n",
    "        return self.criterion(x, self.gt(z_t, t / self.n_T))\n",
    "\n",
    "    def degrade(self, x: torch.Tensor, t: int) -> torch.Tensor:\n",
    "        \"\"\"Row averaging diffusion for a set time step\"\"\"\n",
    "\n",
    "        rows_t = self.rows_t[: int(t[0].item())]\n",
    "\n",
    "        z_t = x\n",
    "\n",
    "        z_t[:, :, rows_t, :] = torch.mean(\n",
    "            x[:, :, rows_t, :], dim=2, keepdim=True\n",
    "        ).expand_as(x[:, :, rows_t, :])\n",
    "\n",
    "        return z_t\n",
    "\n",
    "    def sample(self, n_sample: int, dataset, size, device) -> torch.Tensor:\n",
    "        \"\"\"Algorithm 2 in Bansal et al. (2022)\"\"\"\n",
    "\n",
    "        # num_images = len(dataset)\n",
    "        # idx = random.sample(range(num_images), n_sample)\n",
    "        # z_t = torch.stack([dataset[i][0].clone() for i in idx])\n",
    "        # z_t = z_t.to(device)\n",
    "\n",
    "        # for i in range(n_sample):\n",
    "        #    rows_t = self.rows_t[: self.n_T]\n",
    "        #    z_t[:,:,rows_t,:] = torch.mean(z_t[:,:,rows_t,:]).expand_as(z_t[:,:,rows_t,:])\n",
    "\n",
    "        # z_t = torch.empty((n_sample,1,28,28))\n",
    "\n",
    "        tensor_values = torch.FloatTensor(n_sample, 1, 28, 28).uniform_(-0.5, -0.2)\n",
    "        z_t = torch.mean(tensor_values, dim=2, keepdim=True).expand_as(tensor_values)\n",
    "        z_t = z_t.to(device)\n",
    "\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            i = torch.Tensor([i])\n",
    "            t = i.expand_as(torch.empty(n_sample))\n",
    "            t = t.to(device)\n",
    "            x_hat = self.gt(z_t, t / self.n_T)\n",
    "            z_t -= self.degrade(x_hat, t) - self.degrade(x_hat, t - 1)\n",
    "\n",
    "        return z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "# For testing: (16, 32, 32, 16)\n",
    "# For more capacity (for example): (64, 128, 256, 128, 64)\n",
    "row_avg = Row_Averaging(gt=gt, row_order=1, n_T=28)\n",
    "optim = torch.optim.Adam(row_avg.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "# We wrap our model, optimizer, and dataloaders with `accelerator.prepare`,\n",
    "# which lets HuggingFace's Accelerate handle the device placement and gradient accumulation.\n",
    "row_avg, optim, dataloader = accelerator.prepare(row_avg, optim, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in dataloader:\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    row_avg(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0673: 100%|██████████| 468/468 [00:40<00:00, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m row_avg\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m     xh \u001b[38;5;241m=\u001b[39m \u001b[43mrow_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Can get device explicitly with `accelerator.device`\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     grid \u001b[38;5;241m=\u001b[39m make_grid(xh, nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     32\u001b[0m     avg_losses\u001b[38;5;241m.\u001b[39mappend(avg_loss)\n",
      "Cell \u001b[0;32mIn[8], line 71\u001b[0m, in \u001b[0;36mRow_Averaging.sample\u001b[0;34m(self, n_sample, dataset, size, device)\u001b[0m\n\u001b[1;32m     69\u001b[0m             z_t[i, j, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(z_t[i, j, :])\u001b[38;5;241m.\u001b[39mexpand_as(z_t[i, j, :])\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m             z_t[i, j, :] \u001b[38;5;241m=\u001b[39m \u001b[43mz_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_T, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     74\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt(z_t, i \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_T)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "n_epoch = 50\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    row_avg.train()\n",
    "\n",
    "    pbar = tqdm(dataloader)  # Wrap our loop with a visual progress bar\n",
    "    for x, _ in pbar:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = row_avg(x)\n",
    "\n",
    "        loss.backward()\n",
    "        # ^Technically should be `accelerator.backward(loss)` but not necessary for local training\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        avg_loss = np.average(losses[max(len(losses) - 100, 0) :])\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"loss: {avg_loss:.3g}\"\n",
    "        )  # Show running average of loss in progress bar\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    row_avg.eval()\n",
    "    with torch.no_grad():\n",
    "        xh = row_avg.sample(\n",
    "            16, dataset, (1, 28, 28), accelerator.device\n",
    "        )  # Can get device explicitly with `accelerator.device`\n",
    "        grid = make_grid(xh, nrow=4)\n",
    "        avg_losses.append(avg_loss)\n",
    "        # Save samples to `./contents_custom` directory\n",
    "        save_image(grid, f\"./contents_custom/ddpm_sample_{i:04d}.png\")\n",
    "\n",
    "        # save model\n",
    "        torch.save(row_avg.state_dict(), f\"./ddpm_mnist.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M2CW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
