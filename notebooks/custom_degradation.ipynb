{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Defining a diffusion model with custom degradation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p contents_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/61058798/python-relative-import-in-jupyter-notebook\n",
    "import os, sys\n",
    "\n",
    "dir2 = os.path.abspath(\"\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "from src import funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(75016)\n",
    "np.random.seed(75016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedules(order: int, T: int, type: str) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Returns order and schedule for each row/column in the image.\"\"\"\n",
    "\n",
    "    assert order == 1 or order == 2 or order == 3, \"Order must be either 1 or 2\"\n",
    "\n",
    "    half_point = T // 2 - 1\n",
    "    backward = list(range(13, -1, -1))\n",
    "    forward = list(range(13 + 1, 28))\n",
    "    index = []\n",
    "    if order == 1:\n",
    "        for i in range(half_point + 1):\n",
    "            index.append(forward[i])\n",
    "            index.append(backward[i])\n",
    "        if T % 2 == 1:\n",
    "            index.append(forward[half_point + 1])\n",
    "    elif order == 2:\n",
    "        for i in range(1, half_point + 2):\n",
    "            index.append(backward[-i])\n",
    "            index.append(forward[-i])\n",
    "        if T % 2 == 1:\n",
    "            index.append(forward[-half_point - 2])\n",
    "    else:\n",
    "        # Unique random order\n",
    "        index = random.sample(range(28), 28)\n",
    "\n",
    "    return {type: torch.tensor(index)}\n",
    "\n",
    "\n",
    "def schedules_7(order: int, T: int, type: str) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Returns order and schedule for each 4 wide row in the image.\"\"\"\n",
    "\n",
    "    assert order == 1 or order == 2 or order == 3, \"Order must be either 1 or 2\"\n",
    "\n",
    "    half_point = T // 2 - 1\n",
    "    idx_groups = list(np.array_split(range(28), 7))\n",
    "    backward = list(range(3, -1, -1))\n",
    "    forward = list(range(4, 7))\n",
    "    print(forward, backward)\n",
    "    index = []\n",
    "    if order == 1:\n",
    "        for i in range(half_point + 1):\n",
    "            index.append(idx_groups[backward[i]])\n",
    "            index.append(idx_groups[forward[i]])\n",
    "        if T % 2 == 1:\n",
    "            index.append(idx_groups[backward[half_point + 1]])\n",
    "    elif order == 2:\n",
    "        for i in range(1, half_point + 2):\n",
    "            index.append(idx_groups[forward[-i]])\n",
    "            index.append(idx_groups[backward[-i]])\n",
    "        if T % 2 == 1:\n",
    "            index.append(idx_groups[-half_point - 2])\n",
    "    else:\n",
    "        # Unique random order\n",
    "        idx = random.sample(range(7), 7)\n",
    "        index = [idx_groups[i] for i in idx]\n",
    "\n",
    "    return {type: torch.tensor(index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        *,\n",
    "        expected_shape,\n",
    "        act=nn.GELU,\n",
    "        kernel_size=7,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.LayerNorm((out_channels, *expected_shape)),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        expected_shape=(28, 28),\n",
    "        n_hidden=(64, 128, 64),\n",
    "        kernel_size=7,\n",
    "        last_kernel_size=3,\n",
    "        time_embeddings=16,\n",
    "        act=nn.GELU,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        last = in_channels\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for hidden in n_hidden:\n",
    "            self.blocks.append(\n",
    "                CNNBlock(\n",
    "                    last,\n",
    "                    hidden,\n",
    "                    expected_shape=expected_shape,\n",
    "                    kernel_size=kernel_size,\n",
    "                    act=act,\n",
    "                )\n",
    "            )\n",
    "            last = hidden\n",
    "\n",
    "        # The final layer, we use a regular Conv2d to get the\n",
    "        # correct scale and shape (and avoid applying the activation)\n",
    "        self.blocks.append(\n",
    "            nn.Conv2d(\n",
    "                last,\n",
    "                in_channels,\n",
    "                last_kernel_size,\n",
    "                padding=last_kernel_size // 2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ## This part is literally just to put the single scalar \"t\" into the CNN\n",
    "        ## in a nice, high-dimensional way:\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(time_embeddings * 2, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, 128),\n",
    "            act(),\n",
    "            nn.Linear(128, n_hidden[0]),\n",
    "        )\n",
    "        frequencies = torch.tensor(\n",
    "            [0] + [2 * np.pi * 1.5**i for i in range(time_embeddings - 1)]\n",
    "        )\n",
    "        self.register_buffer(\"frequencies\", frequencies)\n",
    "\n",
    "    def time_encoding(self, t: int) -> torch.Tensor:\n",
    "        phases = torch.concat(\n",
    "            (\n",
    "                torch.sin(t[:, None] * self.frequencies[None, :]),\n",
    "                torch.cos(t[:, None] * self.frequencies[None, :]) - 1,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        return self.time_embed(phases)[:, :, None, None]\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # Shapes of input:\n",
    "        #    x: (batch, chan, height, width)\n",
    "        #    t: (batch,)\n",
    "\n",
    "        embed = self.blocks[0](x)\n",
    "        # ^ (batch, n_hidden[0], height, width)\n",
    "\n",
    "        # Add information about time along the diffusion process\n",
    "        #  (Providing this information by superimposing in latent space)\n",
    "        embed += self.time_encoding(t)\n",
    "        #         ^ (batch, n_hidden[0], 1, 1) - thus, broadcasting\n",
    "        #           to the entire spatial domain\n",
    "\n",
    "        for block in self.blocks[1:]:\n",
    "            embed = block(embed)\n",
    "\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Row_Averaging(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gt,\n",
    "        row_order: int,\n",
    "        grouping: str,\n",
    "        n_T: int,\n",
    "        criterion: nn.Module = nn.MSELoss(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.gt = gt\n",
    "\n",
    "        if grouping == \"7\":\n",
    "            row_schedule = schedules_7(row_order, n_T, \"rows_t\")\n",
    "        else:\n",
    "            row_schedule = schedules(row_order, n_T, \"rows_t\")\n",
    "\n",
    "        # `register_buffer` will track these tensors for device placement, but\n",
    "        # not store them as model parameters. This is useful for constants.\n",
    "        self.register_buffer(\"rows_t\", row_schedule[\"rows_t\"])\n",
    "        self.rows_t  # Exists! Set by register_buffer\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def degrade(self, x: torch.Tensor, t: int) -> torch.Tensor:\n",
    "        \"\"\"Row averaging diffusion for a set time step\"\"\"\n",
    "\n",
    "        rows_t = self.rows_t[: int(t[0].item())]\n",
    "\n",
    "        z_t = x.clone()\n",
    "\n",
    "        # Average the rows\n",
    "        for i in range(x.shape[0]):\n",
    "            for row in rows_t:\n",
    "                z_t[i, :, row, :] = torch.mean(z_t[i, :, row, :])\n",
    "\n",
    "        return z_t\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Row averaging diffusion\"\"\"\n",
    "\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        z_t = x.clone()\n",
    "        for i, idx in enumerate(t):\n",
    "            rows_t = self.rows_t[:idx]\n",
    "            z_t[i, :, rows_t, :] = torch.mean(\n",
    "                z_t[i, :, rows_t, :], dim=2, keepdim=True\n",
    "            ).expand_as(z_t[i, :, rows_t, :])\n",
    "\n",
    "        # We should predict the \"error term\" from this z_t. Loss is what we return.\n",
    "\n",
    "        return self.criterion(x, self.gt(z_t, t / self.n_T))\n",
    "\n",
    "    def sample(self, n_sample: int, dataset, size, device) -> torch.Tensor:\n",
    "        \"\"\"Algorithm 2 in Bansal et al. (2022)\"\"\"\n",
    "\n",
    "        num_images = len(dataset)\n",
    "        idx = random.sample(range(num_images), n_sample)\n",
    "        z_t = torch.stack([dataset[i][0].clone() for i in idx])\n",
    "        z_t = z_t.to(device)\n",
    "\n",
    "        original = z_t.clone()\n",
    "\n",
    "        T = torch.Tensor([self.n_T])\n",
    "        T = T.expand_as(torch.empty(n_sample))\n",
    "        T = T.to(device)\n",
    "\n",
    "        z_t = self.degrade(z_t, T)\n",
    "\n",
    "        degraded = z_t.clone()\n",
    "\n",
    "        # tensor_values = torch.FloatTensor(n_sample, 1, 28, 28).uniform_(-0.5, -0.2)\n",
    "        # z_t = torch.mean(tensor_values, dim=2, keepdim=True).expand_as(tensor_values)\n",
    "        # z_t = z_t.to(device)\n",
    "\n",
    "        z_t_direct = self.gt(z_t, T / self.n_T)\n",
    "\n",
    "        for t in reversed(range(0, self.n_T)):\n",
    "            if t > 0:\n",
    "                t = torch.Tensor([t])\n",
    "                t = t.expand_as(torch.empty(n_sample))\n",
    "                t = t.to(device)\n",
    "                x_hat = self.gt(z_t, t / self.n_T)\n",
    "                z_t = z_t - self.degrade(x_hat, t) + self.degrade(x_hat, t - 1)\n",
    "\n",
    "            else:\n",
    "                t = torch.Tensor([t])\n",
    "                t = t.expand_as(torch.empty(n_sample))\n",
    "                t = t.to(device)\n",
    "                z_t = self.gt(z_t, t / self.n_T)\n",
    "\n",
    "        return original, degraded, z_t_direct, z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Col_Averaging(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gt,\n",
    "        col_order: int,\n",
    "        grouping: str,\n",
    "        n_T: int,\n",
    "        criterion: nn.Module = nn.MSELoss(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.gt = gt\n",
    "\n",
    "        if grouping == \"7\":\n",
    "            col_schedule = schedules_7(col_order, n_T, \"cols_t\")\n",
    "        else:\n",
    "            col_schedule = schedules(col_order, n_T, \"cols_t\")\n",
    "\n",
    "        # `register_buffer` will track these tensors for device placement, but\n",
    "        # not store them as model parameters. This is useful for constants.\n",
    "        self.register_buffer(\"cols_t\", col_schedule[\"cols_t\"])\n",
    "        self.cols_t  # Exists! Set by register_buffer\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def degrade(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Column averaging diffusion for a set time step\"\"\"\n",
    "\n",
    "        # Average the columns\n",
    "        cols_t = self.cols_t[: int(t[0].item())]\n",
    "        z_t = x.clone()\n",
    "        for i in range(x.shape[0]):\n",
    "            for col in cols_t:\n",
    "                z_t[i, :, :, col] = torch.mean(z_t[i, :, :, col])\n",
    "\n",
    "        return z_t\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Column averaging diffusion\"\"\"\n",
    "\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        z_t = x.clone()\n",
    "        for i in range(x.shape[0]):\n",
    "            cols_t = self.cols_t[: t[i]]\n",
    "            for col in cols_t:\n",
    "                z_t[i, :, :, col] = torch.mean(z_t[i, :, :, col])\n",
    "\n",
    "        # We should predict the \"error term\" from this z_t. Loss is what we return.\n",
    "\n",
    "        return self.criterion(x, self.gt(z_t, t / self.n_T))\n",
    "\n",
    "    def sample(self, n_sample: int, dataset, size, device) -> torch.Tensor:\n",
    "        \"\"\"Algorithm 2 in Bansal et al. (2022)\"\"\"\n",
    "\n",
    "        num_images = len(dataset)\n",
    "        idx = random.sample(range(num_images), n_sample)\n",
    "        z_t = torch.stack([dataset[i][0].clone() for i in idx])\n",
    "        z_t = z_t.to(device)\n",
    "        original = z_t.clone()\n",
    "        T = torch.Tensor([self.n_T])\n",
    "        T = T.expand_as(torch.empty(n_sample))\n",
    "        T = T.to(device)\n",
    "\n",
    "        z_t = self.degrade(z_t, T)\n",
    "\n",
    "        z_t_degraded = z_t.clone()\n",
    "        # tensor_values = torch.FloatTensor(n_sample, 1, 28, 28).uniform_(-0.5, -0.2)\n",
    "        # z_t = torch.mean(tensor_values, dim=2, keepdim=True).expand_as(tensor_values)\n",
    "        # z_t = z_t.to(device)\n",
    "\n",
    "        z_t_direct = self.gt(z_t, T / self.n_T)\n",
    "\n",
    "        for t in reversed(range(0, self.n_T)):\n",
    "            if t > 0:\n",
    "                t = torch.Tensor([t])\n",
    "                t = t.expand_as(torch.empty(n_sample))\n",
    "                t = t.to(device)\n",
    "                x_hat = self.gt(z_t, t / self.n_T)\n",
    "                z_t = z_t - self.degrade(x_hat, t) + self.degrade(x_hat, t - 1)\n",
    "\n",
    "            else:\n",
    "                t = torch.Tensor([t])\n",
    "                t = t.expand_as(torch.empty(n_sample))\n",
    "                t = t.to(device)\n",
    "                z_t = self.gt(z_t, t / self.n_T)\n",
    "\n",
    "        return original, z_t_degraded, z_t_direct, z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "# For testing: (16, 32, 32, 16)\n",
    "# For more capacity (for example): (64, 128, 256, 128, 64)\n",
    "dif_model = Col_Averaging(gt=gt, col_order=3, n_T=28, grouping=\"28\")\n",
    "# dif_model = Col_Averaging(gt=gt, col_order=3, n_T=7, grouping='7')\n",
    "# dif_model = Row_Averaging(gt=gt, row_order=3, n_T=7, grouping='7')\n",
    "# dif_model = Row_Averaging(gt=gt, row_order=3, n_T=28, grouping='28')\n",
    "optim = torch.optim.Adam(dif_model.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "# We wrap our model, optimizer, and dataloaders with `accelerator.prepare`,\n",
    "# which lets HuggingFace's Accelerate handle the device placement and gradient accumulation.\n",
    "dif_model, optim, dataloader = accelerator.prepare(dif_model, optim, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in dataloader:\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    dif_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000207: 100%|██████████| 468/468 [01:03<00:00,  7.32it/s]\n",
      "loss: 8.68e-05: 100%|██████████| 468/468 [01:27<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 2\n",
    "orientation = \"col\"\n",
    "hyper_params = \"default\"\n",
    "losses = []\n",
    "avg_losses = []\n",
    "FID = []\n",
    "IS = []\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    dif_model.train()\n",
    "\n",
    "    pbar = tqdm(dataloader)  # Wrap our loop with a visual progress bar\n",
    "    for x, _ in pbar:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = dif_model(x)\n",
    "\n",
    "        loss.backward()\n",
    "        # ^Technically should be `accelerator.backward(loss)` but not necessary for local training\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        avg_loss = np.average(losses[max(len(losses) - 100, 0) :])\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"loss: {avg_loss:.3g}\"\n",
    "        )  # Show running average of loss in progress bar\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    dif_model.eval()\n",
    "    with torch.no_grad():\n",
    "        original, degraded, direct, xh = dif_model.sample(\n",
    "            16, dataset, (1, 28, 28), accelerator.device\n",
    "        )\n",
    "\n",
    "        for i in range(16):\n",
    "            deg_min = torch.min(degraded[i])\n",
    "            deg_max = torch.max(degraded[i])\n",
    "            degraded[i] = (degraded[i] - deg_min) * (0.5 - (-0.5)) / (\n",
    "                deg_max - deg_min\n",
    "            ) - 0.5\n",
    "        grid = make_grid(xh, nrow=4)\n",
    "        grid1 = make_grid(original, nrow=4)\n",
    "        grid2 = make_grid(degraded, nrow=4)\n",
    "        grid3 = make_grid(direct, nrow=4)\n",
    "\n",
    "        # Evaluate the model using FID and Inception Score\n",
    "        avg_losses.append(avg_loss)\n",
    "        fid_temp = funcs.get_fid(dif_model, dataset, 16, accelerator.device)\n",
    "        is_temp = funcs.get_is_custom(\n",
    "            dif_model, dataset, False, 16, accelerator.device\n",
    "        )[0]\n",
    "        FID.append(fid_temp)\n",
    "        IS.append(is_temp)\n",
    "\n",
    "        # fmt: off\n",
    "        # Save samples to `./contents` directory\n",
    "        if i % == 0:\n",
    "            save_image(grid, f\"./contents/custom_sample_{i:04d}.png\") # noqa E231\n",
    "            save_image(grid1, f\"./contents/original_sample_{i:04d}.png\") # noqa E231\n",
    "            save_image(grid2, f\"./contents/degraded_sample_{i:04d}.png\") # noqa E231\n",
    "            save_image(grid3, f\"./contents/direct_sample_{i:04d}.png\") # noqa E231\n",
    "\n",
    "        # fmt: on\n",
    "\n",
    "        # save model\n",
    "        torch.save(\n",
    "            dif_model.state_dict(),\n",
    "            \"./custom_mnist_\"\n",
    "            + str(n_epoch)\n",
    "            + \"_\"\n",
    "            + orientation\n",
    "            + \"_\"\n",
    "            + hyper_params\n",
    "            + \".pth\",\n",
    "        )  # noqa F541"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M2CW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
