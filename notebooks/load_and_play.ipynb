{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p contents_lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/61058798/python-relative-import-in-jupyter-notebook\n",
    "import os, sys\n",
    "\n",
    "dir2 = os.path.abspath(\"\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasbreitburd/anaconda3/envs/M2CW/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from accelerate import Accelerator\n",
    "import src.funcs as funcs\n",
    "from src.cnn_module import CNN\n",
    "from src.custom_deg_module import Col_Averaging, Row_Averaging\n",
    "from src.ddpm_module import DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid(generator, real_data, num_images, device):\n",
    "    with torch.no_grad():\n",
    "        # Sample images from the real images dataset\n",
    "        num_samples = len(real_data)\n",
    "        idx = random.sample(range(num_samples), num_images)\n",
    "        real_img = torch.stack([real_data[i][0].clone() for i in idx])\n",
    "\n",
    "        # Make the image have 3 identical channels\n",
    "        # so that it can be processed by the FID metric\n",
    "        real_img = real_img.to(torch.uint8).expand(-1, 3, -1, -1)\n",
    "\n",
    "        # Sample images from the generator (DDPM)\n",
    "        if generator.__class__.__name__ == \"DDPM\":\n",
    "            gen_img = generator.sample(num_images, (1, 28, 28), device)\n",
    "        else:\n",
    "            _, __, ___, gen_img = generator.sample(\n",
    "                num_images, real_data, (1, 28, 28), device\n",
    "            )\n",
    "\n",
    "        # Make the image have 3 identical channels\n",
    "        gen_img = gen_img.expand(-1, 3, -1, -1)\n",
    "\n",
    "        # Put the images in the same device\n",
    "        gen_img = gen_img.to(real_img.device)\n",
    "\n",
    "        # Initialize the FID metric\n",
    "        fid = FrechetInceptionDistance(normalize=True)\n",
    "\n",
    "        fid.update(real_img, real=True)\n",
    "        fid.update(gen_img, real=False)\n",
    "        fid_score = fid.compute()\n",
    "\n",
    "        return fid_score\n",
    "\n",
    "\n",
    "def get_is(data_source, is_real, num_images, device):\n",
    "    with torch.no_grad():\n",
    "        if is_real:\n",
    "            # Sample images from the real images dataset\n",
    "            num_samples = len(data_source)\n",
    "            idx = random.sample(range(num_samples), num_images)\n",
    "            img = torch.stack([data_source[i][0].clone() for i in idx])\n",
    "            img = img.expand(-1, 3, -1, -1)\n",
    "\n",
    "        else:\n",
    "            # Sample images from the generator (DDPM)\n",
    "            img = data_source.sample(num_images, (1, 28, 28), device)\n",
    "\n",
    "            # Make the image have 3 identical channels\n",
    "            img = img.expand(-1, 3, -1, -1)\n",
    "\n",
    "            img = img.to(\"cpu\")\n",
    "\n",
    "        # Initialize the IS metric\n",
    "        is_score = InceptionScore(\"logits_unbiased\", normalize=True)\n",
    "\n",
    "        is_score.update(img)\n",
    "        is_score = is_score.compute()\n",
    "\n",
    "        return is_score\n",
    "\n",
    "\n",
    "def get_is_custom(generator, data_source, is_real, num_images, device):\n",
    "    with torch.no_grad():\n",
    "        if is_real:\n",
    "            # Sample images from the real images dataset\n",
    "            num_samples = len(data_source)\n",
    "            idx = random.sample(range(num_samples), num_images)\n",
    "            img = torch.stack([data_source[i][0].clone() for i in idx])\n",
    "            img = img.expand(-1, 3, -1, -1)\n",
    "\n",
    "        else:\n",
    "            # Sample images from the generator (DDPM)\n",
    "            _, __, ___, img = generator.sample(\n",
    "                num_images, data_source, (1, 28, 28), device\n",
    "            )\n",
    "\n",
    "            # Make the image have 3 identical channels\n",
    "            img = img.expand(-1, 3, -1, -1)\n",
    "\n",
    "            img = img.to(\"cpu\")\n",
    "\n",
    "        # Initialize the IS metric\n",
    "        is_score = InceptionScore(\"logits_unbiased\", normalize=True)\n",
    "\n",
    "        is_score.update(img)\n",
    "        is_score = is_score.compute()\n",
    "\n",
    "        return is_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "# Plotting functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def plot_losses(losses, avg_losses, num_epochs, model):\n",
    "    \"\"\"!@brief Plot the losses over the training process\n",
    "\n",
    "    @param losses: list of losses\n",
    "    @param avg_losses: list of average losses\n",
    "    @param num_epochs: number of epochs\n",
    "    @param model: used model name\n",
    "\n",
    "    @return None\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.arange(len(losses)) / (len(losses) // num_epochs)\n",
    "    x_epoch = x[:: (len(losses) // num_epochs)].copy() + 1\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, losses, color=\"green\", label=\"Loss\")\n",
    "    plt.plot(\n",
    "        x_epoch,\n",
    "        avg_losses,\n",
    "        linestyle=\"--\",\n",
    "        marker=\"+\",\n",
    "        color=\"black\",\n",
    "        label=\"Epoch average loss\",\n",
    "    )\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.yscale(\"log\")  # Put the y-axis on a log scale\n",
    "    plt.title(f\"Losses over {num_epochs} epochs for {model}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_fid(fid_scores, num_epochs, model):\n",
    "    \"\"\"!@brief Plot the FID scores over the training process\n",
    "\n",
    "    @param fid_scores: list of FID scores\n",
    "    @param num_epochs: number of epochs\n",
    "    @param model: used model name\n",
    "\n",
    "    @return None\n",
    "    \"\"\"\n",
    "    x = np.arange(num_epochs)\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, fid_scores, color=\"green\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"FID\")\n",
    "    plt.title(f\"FID over {num_epochs} epochs for {model}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_is(is_scores, num_epochs, model):\n",
    "    \"\"\"!@brief Plot the IS scores over the training process\n",
    "\n",
    "    @param is_scores: list of IS scores\n",
    "    @param num_epochs: number of epochs\n",
    "    @param model: used model name\n",
    "\n",
    "    @return None\n",
    "    \"\"\"\n",
    "    x = np.arange(num_epochs)\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, is_scores, color=\"green\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"IS\")\n",
    "    plt.title(f\"IS over {num_epochs} epochs for {model}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "\n",
    "dif_model = Col_Averaging(\n",
    "    gt=gt, col_order=3, n_T=7, grouping=\"7\"\n",
    ")  # For column averaging with column grouping\n",
    "# dif_model = Row_Averaging(gt=gt, row_order=3, n_T=7, grouping=\"7\") # For row averaging with row grouping\n",
    "# dif_model = Col_Averaging(gt=gt, col_order=3, n_T=28, grouping=\"28\") # For column averaging with no grouping\n",
    "# dif_model = Row_Averaging(gt=gt, row_order=3, n_T=28, grouping=\"28\") # For row averaging with no grouping\n",
    "# dif_model = DDPM(gt=gt,betas=(1e-4, 0.02), n_T=1000) # For DDPM\n",
    "\n",
    "optim = torch.optim.Adam(dif_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "# We wrap our model, optimizer, and dataloaders with `accelerator.prepare`,\n",
    "# which lets HuggingFace's Accelerate handle the device placement and gradient accumulation.\n",
    "dif_model, optim, dataloader = accelerator.prepare(dif_model, optim, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Col_Averaging(\n",
       "  (gt): CNN(\n",
       "    (blocks): ModuleList(\n",
       "      (0): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((16, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (1): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((32, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (2): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((32, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (3): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((16, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the appropirate model to load:\n",
    "# - ddpm_mnist_{num_epoch}_{hyperparameters}.pth\n",
    "# - custom_mnist_{num_epoch}_col_{hyperparameters}.pth, default_7 or default_28 to set grouping\n",
    "# - custom_mnist_{num_epoch}_row_{hyperparameters}.pth, default_7 or default_28 to set grouping\n",
    "\n",
    "# Load the model\n",
    "dif_model.load_state_dict(\n",
    "    torch.load(\"./ddpm_mnist.pth\", map_location=torch.device(\"cpu\"))\n",
    ")\n",
    "dif_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(75016)\n",
    "np.random.seed(75016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some images\n",
    "\n",
    "# For DDPM\n",
    "# degraded, xh = dif_model.sample(16, (1, 28, 28), accelerator.device)\n",
    "\n",
    "# For custom degradation\n",
    "original, degraded, direct, xh = dif_model.sample(\n",
    "    16, dataset, (1, 28, 28), accelerator.device\n",
    ")\n",
    "\n",
    "# Can get device explicitly with `accelerator.device`\n",
    "for i in range(16):\n",
    "    deg_min = torch.min(degraded[i])\n",
    "    deg_max = torch.max(degraded[i])\n",
    "    # Bump up the contrast, by scaling the values back to -0.5 to 0.5 scale\n",
    "    degraded[i] = (degraded[i] - deg_min) * (0.5 - (-0.5)) / (deg_max - deg_min) - 0.5\n",
    "\n",
    "grid1 = make_grid(degraded, nrow=4)\n",
    "grid = make_grid(xh, nrow=4)\n",
    "grid2 = make_grid(original, nrow=4)\n",
    "grid3 = make_grid(direct, nrow=4)\n",
    "\n",
    "# Plot the original, the degraded, the direct and the restored images\n",
    "save_image(grid1, f\"./contents_lap/degraded_sample.png\")\n",
    "save_image(grid, f\"./contents_lap/generated_sample.png\")\n",
    "save_image(grid2, f\"./contents_lap/original_sample.png\")\n",
    "save_image(grid3, f\"./contents_lap/direct_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasbreitburd/anaconda3/envs/M2CW/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 634.5020141601562\n",
      "IS real: (tensor(1.), tensor(1.0131e-07))\n",
      "IS gen: (tensor(1.), tensor(0.))\n"
     ]
    }
   ],
   "source": [
    "# Compute some metrics\n",
    "\n",
    "# For DDPM\n",
    "# fid_score = get_fid(dif_model, dataset, 1000, accelerator.device)\n",
    "# is_score_real = get_is(dataset, True, 1000, accelerator.device)\n",
    "# is_score_gen = get_is(dif_model, False, 1000, accelerator.device)\n",
    "\n",
    "# For custom degradation\n",
    "fid_score = get_fid(dif_model, dataset, 10, accelerator.device)\n",
    "is_score_real = get_is_custom(dif_model, dataset, True, 10, accelerator.device)\n",
    "is_score_gen = get_is_custom(dif_model, dataset, False, 10, accelerator.device)\n",
    "\n",
    "print(f\"FID: {fid_score}\")\n",
    "print(f\"IS real: {is_score_real}\")\n",
    "print(f\"IS gen: {is_score_gen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs.plot_ddpm_degrade(dataset, 100, (1e-4, 0.02), 1000)\n",
    "funcs.plot_ddpm_degrade(dataset, 900, (1e-4, 0.02), 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M2CW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
