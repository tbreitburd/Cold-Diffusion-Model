{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p contents_lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/61058798/python-relative-import-in-jupyter-notebook\n",
    "import os, sys\n",
    "\n",
    "dir2 = os.path.abspath(\"\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasbreitburd/anaconda3/envs/M2CW/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "import src.funcs as funcs\n",
    "from src.cnn_module import CNN\n",
    "from src.custom_deg_module import Col_Averaging, Row_Averaging\n",
    "from src.ddpm_module import DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we initialise the model from a choice of models, and hyperparameters for DDPM:\n",
    "- Default:\n",
    "    - betas [1e-4,0.02]\n",
    "    - n_T 1000\n",
    "    - n_hidden (16,32,32,16)\n",
    "    - batch_size 128\n",
    "    - activation = nn.GELU\n",
    "- testing2:\n",
    "    - betas = (1e-4, 0.02)\n",
    "    - n_T = 1500\n",
    "    - lr = 4e-4\n",
    "    - n_hidden = (16, 32, 32, 16)\n",
    "    - batch_size = 128\n",
    "    - activation = nn.GELU\n",
    "\n",
    "And for the custom degradation:\n",
    "- Default_7: \n",
    "    - order = 3\n",
    "    - grouping = \"7\"\n",
    "    - n_T = 7\n",
    "    - lr = 2e-4\n",
    "    - n_hidden = (16, 32, 32, 16)\n",
    "    - batch_size = 128\n",
    "- Default_28:\n",
    "    - order = 3\n",
    "    - grouping = \"28\"\n",
    "    - n_T = 28\n",
    "    - lr = 2e-4\n",
    "    - n_hidden = (16, 32, 32, 16)\n",
    "    - batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "\n",
    "dif_model = Col_Averaging(\n",
    "    gt=gt, col_order=3, n_T=28, grouping=\"28\"\n",
    ")  # For column averaging with column grouping\n",
    "\n",
    "# dif_model = Row_Averaging(gt=gt, row_order=3, n_T=7, grouping=\"7\") # For row averaging with row grouping\n",
    "\n",
    "# dif_model = Col_Averaging(gt=gt, col_order=3, n_T=28, grouping=\"28\") # For column averaging with no grouping\n",
    "\n",
    "# dif_model = Row_Averaging(gt=gt, row_order=3, n_T=28, grouping=\"28\") # For row averaging with no grouping\n",
    "\n",
    "# dif_model = DDPM(gt=gt,betas=(1e-4, 0.02), n_T=1000) # For DDPM\n",
    "\n",
    "# Take care for the learning rate:\n",
    "optim = torch.optim.Adam(dif_model.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "# We wrap our model, optimizer, and dataloaders with `accelerator.prepare`,\n",
    "# which lets HuggingFace's Accelerate handle the device placement and gradient accumulation.\n",
    "dif_model, optim, dataloader = accelerator.prepare(dif_model, optim, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Col_Averaging(\n",
       "  (gt): CNN(\n",
       "    (blocks): ModuleList(\n",
       "      (0): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((16, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (1): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((32, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (2): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((32, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (3): CNNBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (1): LayerNorm((16, 28, 28), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the appropirate model to load:\n",
    "# - ddpm_mnist_{num_epoch}_{hyperparameters}.pth\n",
    "# - custom_mnist_{num_epoch}_col_{hyperparameters}.pth, default_7 or default_28 to set grouping\n",
    "# - custom_mnist_{num_epoch}_row_{hyperparameters}.pth, default_7 or default_28 to set grouping\n",
    "\n",
    "# Load the model\n",
    "dif_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"../custom_mnist_80_col_default_28.pth\", map_location=torch.device(\"cpu\")\n",
    "    )\n",
    ")\n",
    "dif_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(75016)\n",
    "np.random.seed(75016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "tensor([[[-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996],\n",
      "         [-0.4001, -0.4450, -0.4456, -0.4666, -0.4695, -0.4765, -0.4802,\n",
      "          -0.4671, -0.4007, -0.4192, -0.2221, -0.3694, -0.2326, -0.2988,\n",
      "          -0.2495, -0.3327, -0.1871, -0.2764, -0.4195, -0.4834, -0.4517,\n",
      "          -0.4481, -0.4510, -0.4827, -0.4873, -0.4767, -0.4622, -0.4996]]],\n",
      "       device='mps:0')\n",
      "tensor(-0.4996, device='mps:0')\n",
      "tensor(-0.1871, device='mps:0')\n",
      "tensor(-0.4984, device='mps:0')\n",
      "tensor(-0.2039, device='mps:0')\n",
      "tensor(-0.4899, device='mps:0')\n",
      "tensor(-0.1595, device='mps:0')\n",
      "tensor(-0.4997, device='mps:0')\n",
      "tensor(-0.1531, device='mps:0')\n",
      "tensor(-0.4877, device='mps:0')\n",
      "tensor(-0.2020, device='mps:0')\n",
      "tensor(-0.4948, device='mps:0')\n",
      "tensor(-0.1941, device='mps:0')\n",
      "tensor(-0.4985, device='mps:0')\n",
      "tensor(-0.2088, device='mps:0')\n",
      "tensor(-0.4920, device='mps:0')\n",
      "tensor(-0.1517, device='mps:0')\n",
      "tensor(-0.4928, device='mps:0')\n",
      "tensor(-0.1675, device='mps:0')\n",
      "tensor(-0.4944, device='mps:0')\n",
      "tensor(-0.1805, device='mps:0')\n",
      "tensor(-0.4929, device='mps:0')\n",
      "tensor(-0.1543, device='mps:0')\n",
      "tensor(-0.4979, device='mps:0')\n",
      "tensor(-0.1807, device='mps:0')\n",
      "tensor(-0.4969, device='mps:0')\n",
      "tensor(-0.1912, device='mps:0')\n",
      "tensor(-0.4969, device='mps:0')\n",
      "tensor(-0.1669, device='mps:0')\n",
      "tensor(-0.4992, device='mps:0')\n",
      "tensor(-0.2089, device='mps:0')\n",
      "tensor(-0.4949, device='mps:0')\n",
      "tensor(-0.1781, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Sample some images\n",
    "\n",
    "# ---------------------------------------------\n",
    "# For DDPM\n",
    "# ---------------------------------------------\n",
    "# degraded, xh = dif_model.sample(16, (1, 28, 28), accelerator.device)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# For custom degradation with conditional sampling\n",
    "# ---------------------------------------------\n",
    "# original, degraded, direct, xh = dif_model.sample(\n",
    "#     16, (1, 28, 28), accelerator.device\n",
    "# )\n",
    "\n",
    "# ---------------------------------------------\n",
    "# For custom degradation with unconditional sampling\n",
    "# ---------------------------------------------\n",
    "degraded, direct, xh = dif_model.sample_unconditional(\n",
    "    16, (1, 28, 28), accelerator.device\n",
    ")\n",
    "\n",
    "\n",
    "# normalise the degraded image for better visualisation\n",
    "for i in range(16):\n",
    "    deg_min = torch.min(degraded[i])\n",
    "    deg_max = torch.max(degraded[i])\n",
    "    # Bump up the contrast, by scaling the values back to -0.5 to 0.5 scale\n",
    "    degraded[i] = (degraded[i] - deg_min) * (0.5 - (-0.5)) / (deg_max - deg_min) - 0.5\n",
    "\n",
    "grid = make_grid(xh, nrow=4)\n",
    "grid1 = make_grid(degraded, nrow=4)\n",
    "# grid2 = make_grid(original, nrow=4)\n",
    "grid3 = make_grid(direct, nrow=4)\n",
    "\n",
    "# Plot the original, the degraded, the direct and the restored images\n",
    "save_image(grid, f\"./contents_lap/generated_sample.png\")\n",
    "save_image(grid1, f\"./contents_lap/degraded_sample.png\")\n",
    "# save_image(grid2, f\"./contents_lap/original_sample.png\")\n",
    "save_image(grid3, f\"./contents_lap/direct_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some metrics\n",
    "\n",
    "# ---------------------------------------------\n",
    "# For DDPM, may need to reduce sample size for time\n",
    "# ---------------------------------------------\n",
    "# fid_score = get_fid(dif_model, dataset, 1000, accelerator.device)\n",
    "# is_score_real = get_is(dataset, True, 1000, accelerator.device)\n",
    "# is_score_gen = get_is(dif_model, False, 1000, accelerator.device)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# For custom degradation\n",
    "# ---------------------------------------------\n",
    "fid_score = funcs.get_fid(dif_model, dataset, 100, accelerator.device)\n",
    "is_score_real = funcs.get_is_custom(dif_model, dataset, True, 100, accelerator.device)\n",
    "is_score_gen = funcs.get_is_custom(dif_model, dataset, False, 100, accelerator.device)\n",
    "\n",
    "print(f\"FID: {fid_score}\")\n",
    "print(f\"IS real: {is_score_real}\")\n",
    "print(f\"IS gen: {is_score_gen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualise the DDPM degradation\n",
    "funcs.plot_ddpm_degrade(dataset, 100, (1e-4, 0.02), 1000)\n",
    "funcs.plot_ddpm_degrade(dataset, 900, (1e-4, 0.02), 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M2CW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
